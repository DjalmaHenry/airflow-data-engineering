<h1 align="center">
  ğŸš€ AIRFLOW DATA ENGINEERING ğŸš€
</h1>

<h2 align="center">
  ğŸ“š Engenharia de dados com Apache Airflow no Google Cloud ğŸ“š
</h2>

### ğŸ¯ Projeto:
Este projeto aproveita a versatilidade do Google Composer e a potÃªncia do Apache Airflow para criar um orquestrador de dados robusto. Usamos uma imagem de Apache Airflow para implantar a orquestraÃ§Ã£o de dados a partir de uma API atÃ© o Google Storage, onde sÃ£o armazenados em formato JSON.

### ğŸ’» Tecnologias utilizadas:
* [Apache Airflow](https://airflow.apache.org/) ğŸŒª
* [Python](https://www.python.org/) ğŸ
* [Google Cloud](https://cloud.google.com/) â˜
* [Docker](https://www.docker.com/) ğŸ³

### ğŸŒ Como implantar na Cloud:
1. Clone o repositÃ³rio.
2. Crie uma conta no Google Cloud Platform (GCP).
3. Configure um usuÃ¡rio administrador no Identity and Access Management (IAM).
4. Crie um ambiente no Google Composer usando uma imagem do Apache Airflow.
5. Carregue os arquivos do pacote Dags que comeÃ§am com "nytimes".
6. Crie um bucket no Google Storage.
7. Na dag, altere o nome do bucket para o que vocÃª criou. Por padrÃ£o, ele Ã© chamado de "airflow-api-backups".
8. Volte para o Composer e acesse o painel do Airflow.
9. No painel, vocÃª verÃ¡ a dag adicionada que vocÃª pode acionar.

### ğŸ’¼ Como rodar localmente:
1. Clone o repositÃ³rio.
2. Instale o Docker em sua mÃ¡quina.
3. Abra o terminal e navegue atÃ© o diretÃ³rio do repositÃ³rio clonado.
4. Execute `docker-compose up -d --build` para construir a imagem e subi-la em um contÃªiner Docker. 
5. Quando os contÃªineres estiverem em execuÃ§Ã£o, acesse `localhost:8080` em seu navegador. VocÃª terÃ¡ acesso ao painel do Airflow com as dags criadas.

### ğŸ‘ CrÃ©ditos:
Este projeto Ã© uma colaboraÃ§Ã£o de:

**Djalma Henrique Silva Lima**  
Github: [DjalmaHenry](https://github.com/DjalmaHenry/)

**Ronny Lima Ribeiro da Silva**  
Github: [ronnylrsd](https://github.com/ronnylrsd)

Vamos juntos fazer a engenharia de dados mais acessÃ­vel e eficiente para todos! ğŸ‰ğŸ™Œ
